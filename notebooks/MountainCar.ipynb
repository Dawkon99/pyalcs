{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACS in Mountain Car environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import local paths\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "sys.path.insert(0, os.path.abspath('../../openai-envs'))\n",
    "\n",
    "from lcs import Perception\n",
    "from lcs.agents import EnvironmentAdapter\n",
    "from lcs.agents.acs2 import ACS2, Configuration, ClassifiersList\n",
    "from lcs.metrics import population_metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load gyms\n",
    "import gym\n",
    "import gym_mountain_car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- ✅ https://www.youtube.com/watch?v=rBzOyjywtPw\n",
    "- ✅ https://repl.it/@MichaelMegliola/MountainCarQ-argmax-only\n",
    "- https://en.wikipedia.org/wiki/Learned_helplessness\n",
    "- maybe some projection of the input space for simpler problem\n",
    "- ✅explore / exploit decay\n",
    "- car final position metric\n",
    "- ✅policy visualization (2d plot)?\n",
    "- ✅extend mountain car to return energy as reward\n",
    "- ✅classifiers plot\n",
    "- profiler co działa najbardziej spowalnia\n",
    "- tile coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "trials = 15000\n",
    "decay = True\n",
    "bins = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Description - https://github.com/openai/gym/wiki/MountainCar-v0\n",
    "\n",
    "![aa](http://gym.openai.com/v2018-02-21/videos/MountainCar-v0-270f34b9-f23e-4d95-a933-4c902b4f4435/poster.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('EnergyMountainCar-v0')\n",
    "# env._max_episode_steps = 1000\n",
    "\n",
    "_range, _low = (env.observation_space.high - env.observation_space.low, env.observation_space.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization of continuous input\n",
    "Values for bins are taken from https://gist.github.com/vblank182/83e29f16755320f82936d211761bfeea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MountainCarAdapter(EnvironmentAdapter):\n",
    "    BINS = bins\n",
    "    \n",
    "    @classmethod\n",
    "    def to_genotype(cls, obs):\n",
    "        return np.round(((obs - _low) / _range) * cls.BINS).astype(int).astype(str).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_fitness(pop):\n",
    "    return np.mean([cl.fitness for cl in pop if cl.is_reliable()])\n",
    "\n",
    "# collect more metrics\n",
    "def mc_metrics(pop, env):\n",
    "    metrics = {}\n",
    "    metrics['avg_fitness'] = avg_fitness(pop)\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building final configuration object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Configuration(\n",
    "            classifier_length=2,\n",
    "            number_of_possible_actions=3,\n",
    "            epsilon=0.9,\n",
    "            beta=0.1,\n",
    "            gamma=0.95,\n",
    "            theta_exp=100,\n",
    "            theta_ga=50,\n",
    "            do_ga=True,\n",
    "            mu=0.03,\n",
    "            metrics_trial_frequency=5,\n",
    "            user_metrics_collector_fcn=mc_metrics,\n",
    "            environment_adapter=MountainCarAdapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 15000 trials, decay=True, bins=12\n"
     ]
    }
   ],
   "source": [
    "print(f'Running {trials} trials, decay={decay}, bins={bins}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 0, 'steps_in_trial': 200, 'reward': 0.46631024260800513, 'avg_fitness': 0.1950212669473081, 'population': 55, 'numerosity': 64, 'reliable': 4}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "agent = ACS2(cfg)\n",
    "population, metrics = agent.explore(env, trials, decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for printing classifier details\n",
    "def print_cl(cl):\n",
    "    action = None\n",
    "    marked = ''\n",
    "    \n",
    "    if cl.action == 0:\n",
    "        action = 'L'\n",
    "    if cl.action == 1:\n",
    "        action = '-'\n",
    "    if cl.action == 2:\n",
    "        action = 'R'\n",
    "    \n",
    "    if cl.is_marked():\n",
    "        marked = '(*)'\n",
    "    \n",
    "    return (f\"{cl.condition} - {action} - {cl.effect} [fit: {cl.fitness:.3f}, r: {cl.r:.2f}, q: {cl.q:.2f}, exp: {cl.exp}, num: {cl.num} {marked}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable = [cl for cl in population if cl.is_reliable()]\n",
    "\n",
    "print(f\"Explore population size: {len(population)}\")\n",
    "print(f\"Reliable classifiers: {len(reliable)}\\n\")\n",
    "\n",
    "for cl in sorted(reliable, key=lambda cl: -cl.fitness)[:50]:\n",
    "    print(print_cl(cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.set_index('trial', inplace=True)\n",
    "\n",
    "metrics_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df['steps_in_trial'].plot(figsize=(14,6), title='Steps in each trial');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "metrics_df['avg_fitness'].rolling(window=window).mean().plot(ax=ax)\n",
    "\n",
    "ax.set_title('Fitness')\n",
    "ax.set_xlabel('Trial')\n",
    "ax.set_ylabel('Avg population fitness')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "metrics_df['reward'].rolling(window=window).mean().plot(ax=ax)\n",
    "\n",
    "ax.set_title('Reward')\n",
    "ax.set_xlabel('Trial')\n",
    "ax.set_ylabel('Reward (energy)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "\n",
    "metrics_df['population'].rolling(window=window).mean().plot(label='population', ax=ax)\n",
    "metrics_df['reliable'].rolling(window=window).mean().plot(label='reliable', ax=ax)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = (\"1\",\"1\")\n",
    "\n",
    "def best_action(obs, population):\n",
    "    matchset = population.form_match_set(Perception(obs))\n",
    "    anticipated_change_cls = [cl for cl in matchset if cl.does_anticipate_change()]\n",
    "\n",
    "    best_classifier = None\n",
    "    if len(anticipated_change_cls) > 0:\n",
    "        random.shuffle(anticipated_change_cls)\n",
    "        best_classifier = max(anticipated_change_cls, key=lambda cl: cl.fitness * cl.num)\n",
    "\n",
    "    if best_classifier is not None:\n",
    "        return best_classifier.action\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "a = best_action(obs, population)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('Set3', 4)\n",
    "\n",
    "BINS = 14\n",
    "EMPTY = -1\n",
    "\n",
    "policy = np.full((BINS, BINS), EMPTY)\n",
    "\n",
    "for pos_bin in range(BINS):\n",
    "    for vel_bin in range(BINS):\n",
    "        obs = (str(pos_bin), str(vel_bin))\n",
    "        action = best_action(obs, population)\n",
    "        policy[pos_bin, vel_bin] = action if action != None else EMPTY\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im = ax.imshow(policy, interpolation='none', cmap=cmap);\n",
    "ax.invert_yaxis()\n",
    "\n",
    "fig.colorbar(im, ticks=[-1, 0, 1, 2])\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Velocity')\n",
    "\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save objects for reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'energy_mountain_car_{trials}_trials_decay_{decay}_bins_{bins}.pickle'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump((population, metrics_df), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
