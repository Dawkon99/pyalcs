{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACS2 in Maze\n",
    "This notebook presents how to integrate ACS2 algorithm with maze environment (using OpenAI Gym interface).\n",
    "\n",
    "Begin with attaching required dependencies. Because most of the work is by now done locally no PIP modules are used (just pure OS paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# General\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# ALCS + Maze environment\n",
    "import sys\n",
    "sys.path.append('/Users/khozzy/Projects/pyalcs')\n",
    "sys.path.append(\"/Users/khozzy/Projects/openai-maze-envs\")\n",
    "\n",
    "# Enable automatic module reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load PyALCS module\n",
    "from alcs import ACS2, ACS2Configuration\n",
    "\n",
    "# Load environments\n",
    "import gym\n",
    "import gym_maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment - Maze\n",
    "We are going to look at provided mazes. Their names starts with \"_Maze..._\" so see what is possible to load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze ID: [MazeF1-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [MazeF2-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [MazeF3-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [MazeF4-v0], non-deterministic: [True], trials: [100]\n",
      "Maze ID: [Maze5-v0], non-deterministic: [True], trials: [100]\n"
     ]
    }
   ],
   "source": [
    "all_envs = [env for env in gym.envs.registry.all()]\n",
    "maze_envs = [env for env in all_envs if env.id.startswith(\"Maze\")]\n",
    "\n",
    "for env in maze_envs:\n",
    "    print(\"Maze ID: [{}], non-deterministic: [{}], trials: [{}]\".format(\n",
    "            env.id, env.nondeterministic, env.trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it looks in action. First we are going to initialize new environment using `gym.make()` instruction from OpenAI Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: MazeF3-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[31mA\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[33m$\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MAZE = \"MazeF3-v0\"\n",
    "\n",
    "# Initialize environment\n",
    "maze = gym.make(MAZE)\n",
    "\n",
    "# Reset it, by putting an agent into random position\n",
    "situation = maze.reset()\n",
    "\n",
    "# Render the state in ASCII\n",
    "maze.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reset()` function puts an agent into random position (on path inside maze) returning current perception.\n",
    "\n",
    "> The perception consists of 8 values representing N, NE, E, SE, S, SW, W, NW directions. It outputs 0 for the path, 1 for the wall and 9 for the reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', '1', '0', '1', '0', '1', '1', '1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show current agents perception\n",
    "situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interact with the environment by performing actions.\n",
    "\n",
    "> Agent can perform 8 actions - moving into different directions.\n",
    "\n",
    "To do so use `step(action)` function. It will return couple interesting information:\n",
    "- new state percepton,\n",
    "- reward for executing move (ie. finding the reward)\n",
    "- is the trial finish,\n",
    "- debug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New state: ('1', '1', '0', '1', '0', '1', '1', '1'), reward: 0, is done: False\n",
      "\n",
      "\u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[31mA\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[33m$\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ACTION = 0 # Move N\n",
    "\n",
    "# Execute action\n",
    "state, reward, done, _ = maze.step(ACTION)\n",
    "\n",
    "# Show new state\n",
    "print(\"New state: {}, reward: {}, is done: {}\".format(state, reward, done))\n",
    "\n",
    "# Render the env one more time after executing step\n",
    "maze.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent - ACS2\n",
    "First provide a helper method for calculating obtained knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_knowledge(maze, population):\n",
    "    transitions = maze.env.get_all_possible_transitions()\n",
    "\n",
    "    # Take into consideration only reliable classifiers\n",
    "    reliable_classifiers = [c for c in population if c.is_reliable()]\n",
    "\n",
    "    # Count how many transitions are anticipated correctly\n",
    "    nr_correct = 0\n",
    "\n",
    "    # For all possible destinations from each path cell\n",
    "    for start, action, end in transitions:\n",
    "        p0 = maze.env.maze.perception(*start)\n",
    "        p1 = maze.env.maze.perception(*end)\n",
    "\n",
    "        if any([True for cl in reliable_classifiers\n",
    "                if cl.predicts_successfully(p0, action, p1)]):\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / len(transitions) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'agent': {'population': 19, 'numerosity': 19, 'reliable': 0, 'fitness': 0.2262354139264028, 'trial': 0, 'steps': 50, 'total_steps': 50}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 36, 'numerosity': 36, 'reliable': 0, 'fitness': 0.20552317021991495, 'trial': 1, 'steps': 50, 'total_steps': 100}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 47, 'numerosity': 47, 'reliable': 0, 'fitness': 0.2052622031562475, 'trial': 2, 'steps': 50, 'total_steps': 150}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 62, 'numerosity': 62, 'reliable': 1, 'fitness': 0.19916248735447778, 'trial': 3, 'steps': 50, 'total_steps': 200}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 64, 'numerosity': 64, 'reliable': 1, 'fitness': 1.5573291489172059, 'trial': 4, 'steps': 13, 'total_steps': 213}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 64, 'numerosity': 64, 'reliable': 1, 'fitness': 2.950281096161973, 'trial': 5, 'steps': 3, 'total_steps': 216}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 64, 'numerosity': 64, 'reliable': 2, 'fitness': 4.36932983646739, 'trial': 6, 'steps': 3, 'total_steps': 219}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 64, 'numerosity': 64, 'reliable': 2, 'fitness': 5.8040334497241455, 'trial': 7, 'steps': 2, 'total_steps': 221}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 66, 'numerosity': 66, 'reliable': 2, 'fitness': 9.59760580063154, 'trial': 8, 'steps': 8, 'total_steps': 229}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 11.2802741921815, 'trial': 9, 'steps': 18, 'total_steps': 247}, 'environment': None, 'performance': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACS2Configuration:\n",
      "\t- Classifier length: [8]\n",
      "\t- Number of possible actions: [8]\n",
      "\t- Classifier wildcard: [#]\n",
      "\t- Perception mapper function: [None]\n",
      "\t- Action mapping dict: [None]\n",
      "\t- Environment metrics function: [None]\n",
      "\t- Performance calculation function: [None] \n",
      "\t- Do GA: [False]\n",
      "\t- Do subsumption: [True]\n",
      "\t- Beta: [0.05]\n",
      "\t- ...\n",
      "\t- Epsilon: [0.5]\n",
      "\t- U_max: [100000]\n",
      "Knowledge learned after executing 10 trials: 9.52%\n"
     ]
    }
   ],
   "source": [
    "CLASSIFIER_LENGTH=8\n",
    "NUMBER_OF_POSSIBLE_ACTIONS=8\n",
    "\n",
    "# Create the empty agent with default configuration\n",
    "cfg = ACS2Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS)\n",
    "\n",
    "\n",
    "agent = ACS2(cfg)\n",
    "\n",
    "# Trials to run the agent\n",
    "TRIALS = 10\n",
    "\n",
    "# Exploration phase\n",
    "maze.reset()\n",
    "population, metrics = agent.explore(maze, TRIALS)\n",
    "\n",
    "# Calculate obtained knowledge\n",
    "knowledge = calculate_knowledge(maze, population)\n",
    "\n",
    "print(cfg)\n",
    "print(\"Knowledge learned after executing {} trials: {:.2f}%\".format(TRIALS, knowledge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a sneak peek into a created list of classifiers. Let's have a look at top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##9#####-2-##1##### @ 0x10ce527f0 \tq: 0.72 \tr: 265.14 \tir: 264.91\n",
      "##9##1##-2-##1##### @ 0x10ce52400 \tq: 0.70 \tr: 265.16 \tir: 264.91\n",
      "####011#-2-####100# @ 0x10ce60c50 \tq: 0.55 \tr: 180.48 \tir: 169.75\n",
      "#####1##-2-######## @ 0x10ce46f28 \tq: 0.36 \tr: 246.98 \tir: 246.21\n",
      "#0###1##-2-######## @ 0x10ce60828 \tq: 0.50 \tr: 176.49 \tir: 176.22\n",
      "#0######-2-######## @ 0x10ce605c0 \tq: 0.50 \tr: 171.03 \tir: 163.97\n",
      "########-2-######## @ 0x10ce306d8 \tq: 0.11 \tr: 219.88 \tir: 203.20\n",
      "##0##0#1-2-##9##1## @ 0x10ce52e48 \tq: 0.89 \tr: 20.13 \tir: 0.00\n",
      "##0##0##-2-##9##1## @ 0x10ce39be0 \tq: 0.74 \tr: 18.91 \tir: 0.00\n",
      "0010011#-1-1101100# @ 0x10ce30668 \tq: 0.93 \tr: 1.22 \tir: 0.00\n"
     ]
    }
   ],
   "source": [
    "population.sort(key=lambda cl: -cl.fitness)\n",
    "\n",
    "for cl in population[:10]:\n",
    "    print(\"{!r} \\tq: {:.2f} \\tr: {:.2f} \\tir: {:.2f}\".format(cl, cl.q, cl.r, cl.ir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can either reuse our previous agent or initialize it one more time passing the initial population of classifiers as *apriori* knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 12.433786827711378, 'trial': 0, 'steps': 2, 'total_steps': 2}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 13.418251879401808, 'trial': 1, 'steps': 3, 'total_steps': 5}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 13.068159402802758, 'trial': 2, 'steps': 50, 'total_steps': 55}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 13.971107838778387, 'trial': 3, 'steps': 1, 'total_steps': 56}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 13.687379408356257, 'trial': 4, 'steps': 50, 'total_steps': 106}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 13.385403964345329, 'trial': 5, 'steps': 50, 'total_steps': 156}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 13.352481935147855, 'trial': 6, 'steps': 50, 'total_steps': 206}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 14.502100058865093, 'trial': 7, 'steps': 2, 'total_steps': 208}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 14.396880601882565, 'trial': 8, 'steps': 50, 'total_steps': 258}, 'environment': None, 'performance': None}\n",
      "INFO:root:{'agent': {'population': 72, 'numerosity': 72, 'reliable': 2, 'fitness': 15.405447683102839, 'trial': 9, 'steps': 3, 'total_steps': 261}, 'environment': None, 'performance': None}\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize agent\n",
    "agent = ACS2(cfg, population)\n",
    "\n",
    "# Reset the environment\n",
    "maze.reset()\n",
    "population, metrics = agent.exploit(maze, TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'agent': {'fitness': 12.433786827711378,\n",
       "   'numerosity': 72,\n",
       "   'population': 72,\n",
       "   'reliable': 2,\n",
       "   'steps': 2,\n",
       "   'total_steps': 2,\n",
       "   'trial': 0},\n",
       "  'environment': None,\n",
       "  'performance': None},\n",
       " {'agent': {'fitness': 13.418251879401808,\n",
       "   'numerosity': 72,\n",
       "   'population': 72,\n",
       "   'reliable': 2,\n",
       "   'steps': 3,\n",
       "   'total_steps': 5,\n",
       "   'trial': 1},\n",
       "  'environment': None,\n",
       "  'performance': None},\n",
       " {'agent': {'fitness': 13.068159402802758,\n",
       "   'numerosity': 72,\n",
       "   'population': 72,\n",
       "   'reliable': 2,\n",
       "   'steps': 50,\n",
       "   'total_steps': 55,\n",
       "   'trial': 2},\n",
       "  'environment': None,\n",
       "  'performance': None}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a helper function for performing multiple experiments and averaging the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(cfg, maze, experiments, trials):\n",
    "    all_metrics = []\n",
    "    \n",
    "    for experiment_id in range(0, experiments):\n",
    "        # Create agent for each experiment independently\n",
    "        agent = ACS2(cfg)\n",
    "        \n",
    "        for trial_id in range(0, trials):\n",
    "            # Execute function\n",
    "            population, metrics = agent.explore(maze)\n",
    "\n",
    "            # Calculate obtained knowledge\n",
    "            knowledge = calculate_knowledge(maze, population)\n",
    "\n",
    "            # Append extra metrics\n",
    "            metrics[0]['experiment_id'] = experiment_id\n",
    "            metrics[0]['trial_id'] = trial_id\n",
    "            metrics[0]['knowledge'] = knowledge\n",
    "        \n",
    "            all_metrics.append(metrics[0])\n",
    "    \n",
    "    # Return last trained agent and all metrics\n",
    "    return agent, all_metrics\n",
    "\n",
    "# Here we are going to reuse the same agent\n",
    "def exploit(agent, maze, experiments, trials):\n",
    "    all_metrics = []\n",
    "    \n",
    "    for experiment_id in range(0, experiments):        \n",
    "        for trial_id in range(0, trials):\n",
    "            # Execute function\n",
    "            population, metrics = agent.exploit(maze)\n",
    "\n",
    "            # Calculate obtained knowledge\n",
    "            knowledge = calculate_knowledge(maze, population)\n",
    "\n",
    "            # Append extra metrics\n",
    "            metrics[0]['experiment_id'] = experiment_id\n",
    "            metrics[0]['trial_id'] = trial_id\n",
    "            metrics[0]['knowledge'] = knowledge\n",
    "        \n",
    "            all_metrics.append(metrics[0])\n",
    "    \n",
    "    # Return last trained agent and all metrics\n",
    "    return all_metrics\n",
    "\n",
    "def experiment(agent, cfg, maze, experiments, explore_trials, exploit_trials):\n",
    "    from copy import copy\n",
    "    \n",
    "    # Run the exploration phase\n",
    "    last_agent, explore_metrics = explore(cfg, maze, experiments, explore_trials)\n",
    "    \n",
    "    # Run the exploitation phase\n",
    "    exploit_metrics = exploit(copy(last_agent), maze, experiments, exploit_trials)\n",
    "    \n",
    "    return last_agent, explore_metrics, exploit_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(metrics):\n",
    "    # Convert to Pandas DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics).groupby(['trial_id']).mean()\n",
    "    metrics_df.drop(['experiment_id', 'trial'], inplace=True, axis=1)\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def convert(explore_metrics, exploit_metric):\n",
    "    explore_df = to_df(explore_metrics)\n",
    "    exploit_df = to_df(exploit_metrics)\n",
    "    \n",
    "    # Reindex dataframes\n",
    "    explore_df.index = range(1, len(explore_df.index)+1)\n",
    "    switch = explore_df.index[-1]\n",
    "    exploit_df.index = range(switch, switch + len(exploit_df.index))\n",
    "    \n",
    "    return explore_df, exploit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym.envs.registration:Making new env: Maze5-v0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "explore() missing 1 required positional argument: 'max_trials'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bd7e08b7af53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Run the experiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m last_agent, explore_metrics, exploit_metrics = experiment(agent, cfg, maze,\n\u001b[0;32m---> 10\u001b[0;31m                                               EXPERIMENTS, TRIALS_EXPLORE, TRIALS_EXPLOIT)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Convert metrics into DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a79fe84255ee>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(agent, cfg, maze, experiments, explore_trials, exploit_trials)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Run the exploration phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mlast_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplore_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplore_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Run the exploitation phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a79fe84255ee>\u001b[0m in \u001b[0;36mexplore\u001b[0;34m(cfg, maze, experiments, trials)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrial_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# Execute function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Calculate obtained knowledge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: explore() missing 1 required positional argument: 'max_trials'"
     ]
    }
   ],
   "source": [
    "agent = ACS2(cfg)\n",
    "maze = gym.make('Maze5-v0')\n",
    "\n",
    "EXPERIMENTS = 2\n",
    "TRIALS_EXPLORE = 400\n",
    "TRIALS_EXPLOIT = 50\n",
    "\n",
    "# Run the experiments\n",
    "last_agent, explore_metrics, exploit_metrics = experiment(agent, cfg, maze,\n",
    "                                              EXPERIMENTS, TRIALS_EXPLORE, TRIALS_EXPLOIT)\n",
    "\n",
    "# Convert metrics into DataFrames\n",
    "explore_df, exploit_df = convert(explore_metrics, exploit_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 5 random averaged metrics\n",
    "explore_df.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show 5 random averaged metrics\n",
    "exploit_df.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Experiments\n",
    "For various mazes visualize\n",
    "- classifiers / reliable classifiers for steps\n",
    "- optimal policy\n",
    "- steps (exploration | exploitation)\n",
    "- knowledge\n",
    "- parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'last_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-427a19189740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_action_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'last_agent' is not defined"
     ]
    }
   ],
   "source": [
    "from alcs.acs2 import ClassifiersList\n",
    "\n",
    "def find_best_classifier(population, situation):\n",
    "    match_set = ClassifiersList.form_match_set(population, situation)\n",
    "    anticipated_change_cls = [cl for cl in match_set if cl.does_anticipate_change()]\n",
    "    \n",
    "    if (len(anticipated_change_cls) > 0):\n",
    "        return max(anticipated_change_cls, key=lambda cl: cl.fitness)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def build_fitness_matrix(env, population):\n",
    "    original = maze.env.maze.matrix\n",
    "    fitness = original.copy()\n",
    "    \n",
    "    # Think about more 'functional' way of doing this\n",
    "    for index, x in np.ndenumerate(original):\n",
    "        # Path - best classfier fitness\n",
    "        if x == 0:\n",
    "            perception = env.env.maze.perception(index[1], index[0])\n",
    "            best_cl = find_best_classifier(population, perception)\n",
    "            if best_cl:\n",
    "                fitness[index] = best_cl.fitness\n",
    "            else:\n",
    "                fitness[index] = -1\n",
    "        \n",
    "        # Wall - fitness = 0\n",
    "        if x == 1:\n",
    "            fitness[index] = 0\n",
    "        \n",
    "        # Reward - inf fitness\n",
    "        if x == 9:\n",
    "            fitness[index] = fitness.max () + 500\n",
    "        \n",
    "    return fitness\n",
    "    \n",
    "def build_action_matrix(env, population):\n",
    "    ACTION_LOOKUP = { \n",
    "        0: '↑', 1: '↗', 2: '→', 3: '↘',\n",
    "        4: '↓', 5: '↙', 6: '←', 7: '↖'\n",
    "    }\n",
    "    \n",
    "    original = maze.env.maze.matrix\n",
    "    action = original.copy().astype(str)\n",
    "    \n",
    "    # Think about more 'functional' way of doing this\n",
    "    for index, x in np.ndenumerate(original):\n",
    "        # Path - best classfier fitness\n",
    "        if x == 0:\n",
    "            perception = env.env.maze.perception(index[1], index[0])\n",
    "            best_cl = find_best_classifier(population, perception)\n",
    "            if best_cl:\n",
    "                action[index] = ACTION_LOOKUP[best_cl.action]\n",
    "            else:\n",
    "                action[index] = '?'\n",
    "        \n",
    "        # Wall - fitness = 0\n",
    "        if x == 1:\n",
    "            action[index] = '\\#'\n",
    "        \n",
    "        # Reward - inf fitness\n",
    "        if x == 9:\n",
    "            action[index] = 'R'\n",
    "        \n",
    "    return action\n",
    "\n",
    "print(build_action_matrix(maze, last_agent.population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(env,agent, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    ax.set_aspect(\"equal\")\n",
    "    \n",
    "    # Handy variables\n",
    "    maze_countours = maze.env.maze.matrix\n",
    "    max_x = maze.env.maze.max_x\n",
    "    max_y = maze.env.maze.max_y\n",
    "    \n",
    "    fitness_matrix = build_fitness_matrix(maze, agent.population)\n",
    "    action_matrix = build_action_matrix(maze, agent.population)\n",
    "    \n",
    "    # Render maze as image\n",
    "    plt.imshow(fitness_matrix, interpolation='none', cmap='Reds', aspect='auto',\n",
    "           extent=[0, max_x, max_y, 0])\n",
    "    \n",
    "    # Add labels to each cell\n",
    "    for (y,x), val in np.ndenumerate(action_matrix):\n",
    "        plt.text(x+0.4, y+0.5, \"${}$\".format(val))\n",
    "    \n",
    "    ax.set_title(\"Policy\")\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "    ax.set_xlim(0, max_x)\n",
    "    ax.set_ylim(max_y, 0)\n",
    "    \n",
    "    ax.set_xticks(range(0, max_x))\n",
    "    ax.set_yticks(range(0, max_y))\n",
    "    \n",
    "    ax.grid(True)\n",
    "\n",
    "plot_policy(maze, last_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knowledge(explore_df, exploit_df, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    explore_df['knowledge'].plot(ax=ax, c='blue')\n",
    "    exploit_df['knowledge'].plot(ax=ax, c='red')\n",
    "    ax.axvline(x=len(explore_df), c='black', linestyle='dashed')\n",
    "        \n",
    "    ax.set_title(\"Achieved knowledge\")\n",
    "    ax.set_xlabel(\"Trial\")\n",
    "    ax.set_ylabel(\"Knowledge [%]\")\n",
    "    ax.set_ylim([0, 105])\n",
    "\n",
    "plot_knowledge(explore_df, exploit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_steps(explore_df, exploit_df, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    explore_df['steps'].plot(ax=ax, c='blue')\n",
    "    exploit_df['steps'].plot(ax=ax, c='red')\n",
    "    ax.axvline(x=len(explore_df), c='black', linestyle='dashed')\n",
    "    \n",
    "    ax.set_title(\"Steps\")\n",
    "    ax.set_xlabel(\"Trial\")\n",
    "    ax.set_ylabel(\"Steps\")\n",
    "    \n",
    "plot_steps(explore_df, exploit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(agent, maze, explore_df, exploit_df):\n",
    "    plt.figure(figsize=(13, 10), dpi=100)\n",
    "    plt.suptitle('ACS2 Performance', fontsize=16)\n",
    "    \n",
    "    ax1 = plt.subplot(221)\n",
    "    plot_policy(maze, agent, ax1)\n",
    "    \n",
    "    ax2 = plt.subplot(222)\n",
    "    plot_knowledge(explore_df, exploit_df, ax2)\n",
    "    \n",
    "    ax3 = plt.subplot(223)\n",
    "    ax3.set_title(\"Classifiers\")\n",
    "    \n",
    "    ax4 = plt.subplot(224)\n",
    "    plot_steps(explore_df, exploit_df, ax4)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.9, wspace=0.3, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_performance(last_agent, maze, explore_df, exploit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ACS2Parameters(do_ga=True)\n",
    "agent = ACS2(params=params)\n",
    "maze = gym.make('MazeF3-v0')\n",
    "\n",
    "EXPERIMENTS = 5\n",
    "TRIALS_EXPLORE = 10\n",
    "TRIALS_EXPLOIT = 5\n",
    "\n",
    "# Run the experiments\n",
    "explore_metrics, exploit_metrics = experiment(agent, params, maze,\n",
    "                                              EXPERIMENTS, TRIALS_EXPLORE, TRIALS_EXPLOIT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
