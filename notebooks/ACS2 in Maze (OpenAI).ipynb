{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACS2 in Maze\n",
    "This notebook presents how to integrate ACS2 algorithm with maze environment (using OpenAI Gym interface).\n",
    "\n",
    "Begin with attaching required dependencies. Because most of the work is by now done locally no PIP modules are used (just pure OS paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# General\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To avoid Type3 fonts in generated pdf file\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# Logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "# ALCS + Custom environments\n",
    "import sys\n",
    "sys.path.append('/Users/khozzy/Projects/pyalcs')\n",
    "sys.path.append(\"/Users/khozzy/Projects/openai-envs\")\n",
    "\n",
    "# Enable automatic module reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load PyALCS module\n",
    "from lcs.agents.acs2 import ACS2, Configuration, ClassifiersList\n",
    "\n",
    "# Load environments\n",
    "import gym\n",
    "import gym_maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment - Maze\n",
    "We are going to look at provided mazes. Their names starts with \"_Maze..._\" or \"_Woods..._\" so see what is possible to load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze ID: [MazeF1-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [MazeF2-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [MazeF3-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [MazeF4-v0], non-deterministic: [True], trials: [100]\n",
      "Maze ID: [Maze4-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [Maze5-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [Maze6-v0], non-deterministic: [True], trials: [100]\n",
      "Maze ID: [Woods1-v0], non-deterministic: [False], trials: [100]\n",
      "Maze ID: [Woods14-v0], non-deterministic: [False], trials: [100]\n"
     ]
    }
   ],
   "source": [
    "# Custom function for obtaining available environments\n",
    "filter_envs = lambda env: env.id.startswith(\"Maze\") or env.id.startswith(\"Woods\")\n",
    "\n",
    "all_envs = [env for env in gym.envs.registry.all()]\n",
    "maze_envs = [env for env in all_envs if filter_envs(env)]\n",
    "\n",
    "for env in maze_envs:\n",
    "    print(\"Maze ID: [{}], non-deterministic: [{}], trials: [{}]\".format(\n",
    "            env.id, env.nondeterministic, env.trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it looks in action. First we are going to initialize new environment using `gym.make()` instruction from OpenAI Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[33m$\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[31mA\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#MAZE = \"Woods14-v0\"\n",
    "MAZE = \"Maze5-v0\"\n",
    "\n",
    "# Initialize environment\n",
    "maze = gym.make(MAZE)\n",
    "\n",
    "# Reset it, by putting an agent into random position\n",
    "situation = maze.reset()\n",
    "\n",
    "# Render the state in ASCII\n",
    "maze.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reset()` function puts an agent into random position (on path inside maze) returning current perception.\n",
    "\n",
    "> The perception consists of 8 values representing N, NE, E, SE, S, SW, W, NW directions. It outputs 0 for the path, 1 for the wall and 9 for the reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', '1', '1', '1', '1', '1', '1', '0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show current agents perception\n",
    "situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interact with the environment by performing actions.\n",
    "\n",
    "> Agent can perform 8 actions - moving into different directions.\n",
    "\n",
    "To do so use `step(action)` function. It will return couple interesting information:\n",
    "- new state percepton,\n",
    "- reward for executing move (ie. finding the reward)\n",
    "- is the trial finish,\n",
    "- debug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New state: ('1', '1', '1', '1', '0', '1', '0', '0'), reward: 0, is done: False\n",
      "\n",
      "\u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[33m$\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[31mA\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m \u001b[30m■\u001b[0m\n",
      "\u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ACTION = 0 # Move N\n",
    "\n",
    "# Execute action\n",
    "state, reward, done, _ = maze.step(ACTION)\n",
    "\n",
    "# Show new state\n",
    "print(\"New state: {}, reward: {}, is done: {}\".format(state, reward, done))\n",
    "\n",
    "# Render the env one more time after executing step\n",
    "maze.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent - ACS2\n",
    "First provide a helper method for calculating obtained knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_knowledge(maze, population):\n",
    "    transitions = maze.env.get_all_possible_transitions()\n",
    "\n",
    "    # Take into consideration only reliable classifiers\n",
    "    reliable_classifiers = [c for c in population if c.is_reliable()]\n",
    "\n",
    "    # Count how many transitions are anticipated correctly\n",
    "    nr_correct = 0\n",
    "\n",
    "    # For all possible destinations from each path cell\n",
    "    for start, action, end in transitions:\n",
    "        p0 = maze.env.maze.perception(*start)\n",
    "        p1 = maze.env.maze.perception(*end)\n",
    "\n",
    "        if any([True for cl in reliable_classifiers\n",
    "                if cl.predicts_successfully(p0, action, p1)]):\n",
    "            nr_correct += 1\n",
    "\n",
    "    return {\n",
    "        'knowledge': nr_correct / len(transitions) * 100.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_LENGTH=8\n",
    "NUMBER_OF_POSSIBLE_ACTIONS=8\n",
    "\n",
    "# Define agent's default configuration\n",
    "cfg = Configuration(\n",
    "    classifier_length=CLASSIFIER_LENGTH,\n",
    "    number_of_possible_actions=NUMBER_OF_POSSIBLE_ACTIONS,\n",
    "    performance_fcn=calculate_knowledge)\n",
    "\n",
    "# Define agent\n",
    "agent = ACS2(cfg)\n",
    "\n",
    "# Exploration phase\n",
    "maze.reset()\n",
    "population, metrics = agent.explore(maze, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a sneak peek into a created list of classifiers. Let's have a look at top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9####010-0-1####101 @ 0x118db1048 \tq: 1.00 \tr: 989.60 \tir: 989.59\n",
      "01110001-0-9#####10 @ 0x118e27eb8 \tq: 1.00 \tr: 862.58 \tir: 0.00\n",
      "1000#101-1-9111#010 @ 0x10e90e080 \tq: 0.97 \tr: 727.73 \tir: 0.00\n",
      "000###10-1-#11###01 @ 0x118ee09e8 \tq: 1.00 \tr: 703.06 \tir: 0.00\n",
      "000#0#10-1-#11###01 @ 0x118df3f60 \tq: 0.99 \tr: 704.06 \tir: 0.00\n",
      "000#0010-1-#11###01 @ 0x118ee08d0 \tq: 0.99 \tr: 703.43 \tir: 0.00\n",
      "000##010-1-#11###01 @ 0x118dffd68 \tq: 0.99 \tr: 703.38 \tir: 0.00\n",
      "10000101-1-9111#010 @ 0x118e1bb00 \tq: 0.95 \tr: 727.75 \tir: 0.00\n",
      "11#01100-3-00#1001# @ 0x118f05550 \tq: 0.99 \tr: 411.68 \tir: 0.00\n",
      "1100110#-3-00#1001# @ 0x118ed3668 \tq: 1.00 \tr: 407.64 \tir: 0.00\n"
     ]
    }
   ],
   "source": [
    "population.sort(key=lambda cl: -cl.fitness)\n",
    "\n",
    "for cl in population[:10]:\n",
    "    print(\"{!r} \\tq: {:.2f} \\tr: {:.2f} \\tir: {:.2f}\".format(cl, cl.q, cl.r, cl.ir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can either reuse our previous agent or initialize it one more time passing the initial population of classifiers as *apriori* knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize agent using defined configuration and population\n",
    "agent = ACS2(cfg, population)\n",
    "\n",
    "# Reset the environment\n",
    "maze.reset()\n",
    "population, metrics = agent.exploit(maze, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'agent': {'population': 475,\n",
       "   'numerosity': 475,\n",
       "   'reliable': 60,\n",
       "   'fitness': 55.7429842739833,\n",
       "   'trial': 0,\n",
       "   'steps': 5,\n",
       "   'total_steps': 5},\n",
       "  'environment': None,\n",
       "  'performance': {'knowledge': 14.383561643835616}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metrics_to_df(explore_metrics, exploit_metrics):\n",
    "    def extract_details(row):\n",
    "        row['trial'] = row['agent']['trial']\n",
    "        row['steps'] = row['agent']['steps']\n",
    "        row['numerosity'] = row['agent']['numerosity']\n",
    "        row['reliable'] = row['agent']['reliable']\n",
    "        row['knowledge'] = row['performance']['knowledge']\n",
    "        return row\n",
    "    \n",
    "    # Load both metrics into data frame\n",
    "    explore_df = pd.DataFrame(explore_metrics)\n",
    "    exploit_df = pd.DataFrame(exploit_metrics)\n",
    "    \n",
    "    # Mark them with specific phase\n",
    "    explore_df['phase'] = 'explore'\n",
    "    exploit_df['phase'] = 'exploit'\n",
    "    \n",
    "    # Extract details\n",
    "    explore_df = explore_df.apply(extract_details, axis=1)\n",
    "    exploit_df = exploit_df.apply(extract_details, axis=1)\n",
    "    \n",
    "    # Adjuts exploit trial counter\n",
    "    exploit_df['trial'] = exploit_df.apply(lambda r: r['trial']+len(explore_df), axis=1)\n",
    "    \n",
    "    # Concatenate both dataframes\n",
    "    df = pd.concat([explore_df, exploit_df])\n",
    "    df.drop(['agent', 'environment', 'performance'], axis=1, inplace=True)\n",
    "    df.set_index('trial', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For various mazes visualize\n",
    "- classifiers / reliable classifiers for steps\n",
    "- optimal policy\n",
    "- steps (exploration | exploitation)\n",
    "- knowledge\n",
    "- parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_classifier(population, situation, cfg):\n",
    "    match_set = ClassifiersList.form_match_set(population, situation, cfg)\n",
    "    anticipated_change_cls = [cl for cl in match_set if cl.does_anticipate_change()]\n",
    "    \n",
    "    if (len(anticipated_change_cls) > 0):\n",
    "        return max(anticipated_change_cls, key=lambda cl: cl.fitness)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def build_fitness_matrix(env, population, cfg):\n",
    "    original = env.env.maze.matrix\n",
    "    fitness = original.copy()\n",
    "    \n",
    "    # Think about more 'functional' way of doing this\n",
    "    for index, x in np.ndenumerate(original):\n",
    "        # Path - best classfier fitness\n",
    "        if x == 0:\n",
    "            perception = env.env.maze.perception(index[1], index[0])\n",
    "            best_cl = find_best_classifier(population, perception, cfg)\n",
    "            if best_cl:\n",
    "                fitness[index] = best_cl.fitness\n",
    "            else:\n",
    "                fitness[index] = -1\n",
    "        \n",
    "        # Wall - fitness = 0\n",
    "        if x == 1:\n",
    "            fitness[index] = 0\n",
    "        \n",
    "        # Reward - inf fitness\n",
    "        if x == 9:\n",
    "            fitness[index] = fitness.max () + 500\n",
    "        \n",
    "    return fitness\n",
    "    \n",
    "def build_action_matrix(env, population, cfg):\n",
    "    ACTION_LOOKUP = { \n",
    "        0: u'↑', 1: u'↗', 2: u'→', 3: u'↘',\n",
    "        4: u'↓', 5: u'↙', 6: u'←', 7: u'↖'\n",
    "    }\n",
    "    \n",
    "    original = env.env.maze.matrix\n",
    "    action = original.copy().astype(str)\n",
    "    \n",
    "    # Think about more 'functional' way of doing this\n",
    "    for index, x in np.ndenumerate(original):\n",
    "        # Path - best classfier fitness\n",
    "        if x == 0:\n",
    "            perception = env.env.maze.perception(index[1], index[0])\n",
    "            best_cl = find_best_classifier(population, perception, cfg)\n",
    "            if best_cl:\n",
    "                action[index] = ACTION_LOOKUP[best_cl.action]\n",
    "            else:\n",
    "                action[index] = '?'\n",
    "        \n",
    "        # Wall - fitness = 0\n",
    "        if x == 1:\n",
    "            action[index] = '\\#'\n",
    "        \n",
    "        # Reward - inf fitness\n",
    "        if x == 9:\n",
    "            action[index] = 'R'\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot constants\n",
    "TITLE_TEXT_SIZE=24\n",
    "AXIS_TEXT_SIZE=18\n",
    "LEGEND_TEXT_SIZE=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(env, agent, cfg, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    ax.set_aspect(\"equal\")\n",
    "    \n",
    "    # Handy variables\n",
    "    maze_countours = maze.env.maze.matrix\n",
    "    max_x = env.env.maze.max_x\n",
    "    max_y = env.env.maze.max_y\n",
    "    \n",
    "    fitness_matrix = build_fitness_matrix(env, agent.population, cfg)\n",
    "    action_matrix = build_action_matrix(env, agent.population, cfg)\n",
    "    \n",
    "    # Render maze as image\n",
    "    plt.imshow(fitness_matrix, interpolation='nearest', cmap='Reds', aspect='auto',\n",
    "           extent=[0, max_x, max_y, 0])\n",
    "    \n",
    "    \n",
    "    # Add labels to each cell\n",
    "    for (y,x), val in np.ndenumerate(action_matrix):\n",
    "        plt.text(x+0.4, y+0.5, \"${}$\".format(val))\n",
    "    \n",
    "    ax.set_title(\"Policy\", fontsize=TITLE_TEXT_SIZE)\n",
    "    ax.set_xlabel('x', fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylabel('y', fontsize=AXIS_TEXT_SIZE)\n",
    "\n",
    "    ax.set_xlim(0, max_x)\n",
    "    ax.set_ylim(max_y, 0)\n",
    "    \n",
    "    ax.set_xticks(range(0, max_x))\n",
    "    ax.set_yticks(range(0, max_y))\n",
    "    \n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knowledge(df, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    explore_df = df.query(\"phase == 'explore'\")\n",
    "    exploit_df = df.query(\"phase == 'exploit'\")\n",
    "        \n",
    "    explore_df['knowledge'].plot(ax=ax, c='blue')\n",
    "    exploit_df['knowledge'].plot(ax=ax, c='red')\n",
    "    ax.axvline(x=len(explore_df), c='black', linestyle='dashed')\n",
    "        \n",
    "    ax.set_title(\"Achieved knowledge\", fontsize=TITLE_TEXT_SIZE)\n",
    "    ax.set_xlabel(\"Trial\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylabel(\"Knowledge [%]\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylim([0, 105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_steps(df, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    explore_df = df.query(\"phase == 'explore'\")\n",
    "    exploit_df = df.query(\"phase == 'exploit'\")\n",
    "    \n",
    "    explore_df['steps'].plot(ax=ax, c='blue', linewidth=.5)\n",
    "    exploit_df['steps'].plot(ax=ax, c='red', linewidth=0.5)\n",
    "    ax.axvline(x=len(explore_df), c='black', linestyle='dashed')\n",
    "    \n",
    "    ax.set_title(\"Steps\", fontsize=TITLE_TEXT_SIZE)\n",
    "    ax.set_xlabel(\"Trial\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylabel(\"Steps\", fontsize=AXIS_TEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classifiers(df, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    explore_df = df.query(\"phase == 'explore'\")\n",
    "    exploit_df = df.query(\"phase == 'exploit'\")\n",
    "    \n",
    "    df['numerosity'].plot(ax=ax, c='blue')\n",
    "    df['reliable'].plot(ax=ax, c='red')    \n",
    "    \n",
    "    ax.axvline(x=len(explore_df), c='black', linestyle='dashed')\n",
    "    \n",
    "    ax.set_title(\"Classifiers\", fontsize=TITLE_TEXT_SIZE)\n",
    "    ax.set_xlabel(\"Trial\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.set_ylabel(\"Classifiers\", fontsize=AXIS_TEXT_SIZE)\n",
    "    ax.legend(fontsize=LEGEND_TEXT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(agent, maze, metrics_df, cfg, env_name):\n",
    "    plt.figure(figsize=(13, 10), dpi=100)\n",
    "    plt.suptitle(f'ACS2 Performance in {env_name} environment', fontsize=32)\n",
    "    \n",
    "    ax1 = plt.subplot(221)\n",
    "    plot_policy(maze, agent, cfg, ax1)\n",
    "    \n",
    "    ax2 = plt.subplot(222)\n",
    "    plot_knowledge(metrics_df, ax2)\n",
    "    \n",
    "    ax3 = plt.subplot(223)\n",
    "    plot_classifiers(metrics_df, ax3)\n",
    "    \n",
    "    ax4 = plt.subplot(224)\n",
    "    plot_steps(metrics_df, ax4)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.86, wspace=0.3, hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maze5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze5 = gym.make('Maze5-v0')\n",
    "\n",
    "# explore\n",
    "agent_maze5 = ACS2(cfg)\n",
    "population_maze5_explore, metrics_maze5_explore = agent_maze5.explore(maze5, 3000)\n",
    "\n",
    "# exploit\n",
    "agent_maze5 = ACS2(cfg, population_maze5_explore)\n",
    "_, metrics_maze5_exploit = agent_maze5.exploit(maze5, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze5_metrics_df = parse_metrics_to_df(metrics_maze5_explore, metrics_maze5_exploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_performance(agent_maze5, maze5, maze5_metrics_df, cfg, 'Maze5')\n",
    "# plt.savefig('images/maze5.pdf', format='pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woods14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woods14 = gym.make('Woods14-v0')\n",
    "\n",
    "# explore\n",
    "agent_woods14 = ACS2(cfg)\n",
    "population_woods14_explore, metrics_woods14_explore = agent_woods14.explore(woods14, 1000)\n",
    "\n",
    "# exploit\n",
    "agent_woods14 = ACS2(cfg, population_woods14_explore)\n",
    "_, metrics_woods14_exploit = agent_woods14.exploit(woods14, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woods14_metrics_df = parse_metrics_to_df(metrics_woods14_explore, metrics_woods14_exploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(agent_woods14, woods14, woods14_metrics_df, cfg, 'Woods14')\n",
    "plt.savefig('images/woods14.pdf', format='pdf', dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
